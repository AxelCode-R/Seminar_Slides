---
title: "Particel Swarm Optimization (PSO)"
output:
  ioslides_presentation:
    css: style.css
date: '2022-11-07'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(data.table)

for(src in list.files("R/")){
  sourde(paste0("R/", src))
}
```


## Agenda

- Entstehung
- Standard PSO
- Beispiel 2D
- Anwendungen


## Entstehung

- Erfunden von Russell Eberhardt und James Kennedy in 1995
<div class="columns-2"> 
<div class="centered">
![](img/Eberhardt.png){width=180px} 
<div/>
<div/>
<div class="columns-2"> 
<div class="centered">
![](img/Kennedy.jpg){width=200px} 
<div/>
<div/>
- Analogie zu natürlichen Vogelschwärmen
- PSO ist eine naturanaloge Metaheuristik
- Erste Anwendung in der Teilchenphysik

<div class="notes">
- Metaheuristik ist Optimierungsveerfahren
- (bild1) Russell C. Eberhart professor of Electrical and Computer Engineering
- (bild2) James Kennedy (social psychologist)
</div>





## Standard PSO (SPSO)
- Minimierungsproblem: Kostenfunktion $f: \mathbb{R}^n \rightarrow \mathbb{R}$
- Partikel bewegen sich im $\mathbb{R}^n$
- Partikel teilen sich Informationen
- Partikel haben ein Gedächtnis
- Partikel ändern Ihre Geschwindigkeit abhängig von 3 Faktoren
- Iteriere bis das Minimum erreicht ist



## SPSO Formel

1. Initialisiere zufällige Positionen $x^{k, i}$ und Geschwindigkeiten $v^{k, i}$ der Partikel $k$ in Iteration $i=0$

2. Evaluiere die Kostenfunktion mit der Position jedes Partikels

3. Speicher die bisher beste Position in $g_{best}^i$

4. Speicher die bisher beste Position pro Partikel in $p_{best}^{k,i}$

5. Iterationsschritt $i \rightarrow i+1$ pro Partikel $k$:
$$
\begin{aligned}
  v^{k, i+1} &= w \cdot v^{k, i} + c_p \cdot r_1 \cdot (p_{best}^{k,i}-x^{k,i}) + c_g \cdot r_2 \cdot (g_{best}^{k,i}-x^{k,i}) \\
  x^{k, i+1} &= x^{k, i} + v^{k, i+1}
\end{aligned}
$$
6. Wiederhole Schritt 2-5 bis die Abbruchbedingung erreicht ist



## SPSO Zeitschritt
$$
\begin{aligned}
  v^{k, i+1} &= w \cdot v^{k, i} + c_p \cdot r_1 \cdot (p_{best}^{k,i}-x^{k,i}) + c_g \cdot r_2 \cdot (g_{best}^{k,i}-x^{k,i}) \\
  x^{k, i+1} &= x^{k, i} + v^{k, i+1}
\end{aligned}
$$
\
<div class="centered">
![](img/PSO_richtungsvekoren.png)
</div>

<div class="notes">
- bild: https://www.intechopen.com/chapters/69586
</div>



## Einfaches Beispiel

Zielfunktion:  
$$
\begin{aligned}
  f(x, y) =& -20\cdot e^{-0.2 \cdot \sqrt{0.5 \cdot ((x-1)^2 + (y-1)^2)}} \\
  & \ - e^{0.5 \cdot ( cos(2\cdot \pi \cdot x) + cos(2\cdot \pi \cdot y))} + e + 20
\end{aligned}
$$
Aufgabe:  
Minimiere $f(x,y)$ mit $-10 \leq x \leq 10$ und $-10 \leq y \leq 10$

[PSO App](PSO App)


## Nebenbedingungen

Beispiele:  

- Summe soll 100% ergeben

- Summe der Gewichte von Elementen mit Ausprägung A soll weniger als 20% betragen

- Kosten sollen kleiner als 100 Euro sein

- Weniger als 20 Elemente sollen ungleich Null sein

- ...

Methoden:  

- Penalty

- Verwerfen von ungültigen Lösungen

- Reparieren von ungültigen Lösungen



## Penalty Methode

Alte Zielfunktion: $f(x)$

Bruch von Nebenbedingungen: $g(x)$

Neue Zielfunktion: $z(x) = f(x) + g(x)$

Beispiel für gängige Nebenbedingungen:
$$
  A^T \times x \geq b_0
$$
Dann könnte $g(x)$ wie folgt aussehen:
$$
  g(x) = ||\vec{\lambda}( A^T \times x - b_0 )||_2^2
$$
mit elementweiser Anwendung von
$$
  \lambda(x) = \begin{cases}
  0 &\text{ if }x \geq 0\\
  x &\text{ if }x < 0
  \end{cases}
$$















